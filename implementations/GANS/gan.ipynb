{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #-------------------------- Goal --------------------------------#\n",
    "\n",
    "1) Build the generator and discriminator components of a GAN from scratch.\n",
    "2) Create generator and discriminator loss functions.\n",
    "3) Train your GAN and visualize the generated images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "torch.manual_seed(0) # Set for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in a uniform grid.\n",
    "    '''\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batches\n",
    "<li>While you could train your model after generating one image, it is extremely inefficient and leads to less stable training. In GANs, and in machine learning in general, you will process multiple images per training step. These are called batches.\n",
    "</li>\n",
    "<li>\n",
    "This means that your generator will generate an entire batch of images and receive the discriminator's feedback on each before updating the model. The same goes for the discriminator, it will calculate its loss on the entire batch of generated images as well as on the reals before the model is updated.\n",
    "</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "<li> The first step is to build the generator component.</li>\n",
    "<li>\n",
    "we will start by creating a function to make a single layer/block for the generator's neural network. Each block should include a linear transformation to map to another shape, a batch normalization for stabilization, and finally a non-linear activation function (you use a ReLU here) so the output can be transformed in complex ways.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_block(input_dim, output_dim):\n",
    "    \"\"\"\n",
    "    When inplace=True is passed to nn.LeakyReLU(), it means that the operation should be performed \"in place\", \n",
    "    which means that the input tensor is modified in place without creating a new tensor.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the generator block function\n",
    "def test_gen_block(in_features, out_features, num_test=1000):\n",
    "    block = get_generator_block(in_features, out_features)\n",
    "\n",
    "    # Check the three parts\n",
    "    assert len(block) == 3\n",
    "    assert type(block[0]) == nn.Linear\n",
    "    assert type(block[1]) == nn.BatchNorm1d\n",
    "    assert type(block[2]) == nn.ReLU\n",
    "    \n",
    "    # Check the output shape\n",
    "    test_input = torch.randn(num_test, in_features)\n",
    "    test_output = block(test_input)\n",
    "    assert tuple(test_output.shape) == (num_test, out_features)\n",
    "    assert test_output.std() > 0.55\n",
    "    assert test_output.std() < 0.65\n",
    "\n",
    "test_gen_block(25, 12)\n",
    "test_gen_block(15, 28)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Lets Create Generator Class\n",
    "<li>Takes the random noise and generate image with the Proper Image dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, noise_dimension=10, hidden_units=64, image_size=28*28):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.gen = nn.Sequential(\n",
    "\n",
    "            # First layer Takes the noise as the input with 64 neurons/hidden units\n",
    "            get_generator_block(input_dim=noise_dimension, output_dim=hidden_units),\n",
    "            # 2nd layer\n",
    "            get_generator_block(input_dim=hidden_units, output_dim=hidden_units*2),\n",
    "            # 3rd layer\n",
    "            get_generator_block(input_dim=hidden_units*2, output_dim=hidden_units*2),\n",
    "            # 4th layer \n",
    "            get_generator_block(input_dim=hidden_units*2, output_dim=hidden_units*2),\n",
    "            # 5th layer\n",
    "            get_generator_block(input_dim=hidden_units*2, output_dim=image_size),\n",
    "            # sigmoid activation bcz the output of the above layer is flattended vector with elements value ranges from - to + we will make them in between 0 and 1\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, noise):\n",
    "            # noise: a noise tensor with dimensions(num_samples,noise_dimension)\n",
    "            return self.gen(noise)\n",
    "        \n",
    "    def get_gen(self):\n",
    "            return  self.gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = Generator().get_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.__getitem__(4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the generator class\n",
    "def test_generator(noise_dim, image_dim, units, num_test=10000):\n",
    "    gen = Generator(noise_dimension=noise_dim,hidden_units=units, image_size=image_dim).get_gen()\n",
    "    \n",
    "    # Check there are six modules in the sequential part\n",
    "    assert len(gen) == 6\n",
    "    assert str(gen.__getitem__(4)[0]).replace(' ', '') == f'Linear(in_features={units * 2},out_features={image_dim},bias=True)'\n",
    "    assert str(gen.__getitem__(5)).replace(' ', '') == 'Sigmoid()'\n",
    "    test_input = torch.randn(num_test, noise_dim)\n",
    "    test_output = gen(test_input)\n",
    "\n",
    "    # Check that the output shape is correct\n",
    "    assert tuple(test_output.shape) == (num_test, image_dim)\n",
    "    assert test_output.max() < 1, \"Make sure to use a sigmoid\"\n",
    "    assert test_output.min() > 0, \"Make sure to use a sigmoid\"\n",
    "    assert test_output.std() > 0.05, \"Don't use batchnorm here\"\n",
    "    assert test_output.std() < 0.15, \"Don't use batchnorm here\"\n",
    "\n",
    "test_generator(10, 20, 10)\n",
    "test_generator(20, 8, 24)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise\n",
    "<li>To be able to use your generator, you will need to be able to create noise vectors. The noise vector z has the important role of making sure the images generated from the same class don't all look the same -- think of it as a random seed. You will generate it randomly using PyTorch by sampling random numbers from the normal distribution. Since multiple images will be processed per pass, you will generate all the noise vectors at once.\n",
    "\n",
    "<li>Note that whenever you create a new tensor using torch.ones, torch.zeros, or torch.randn, you either need to create it on the target device, e.g. torch.ones(3, 3, device=device), or move it onto the target device using torch.ones(3, 3).to(device). You do not need to do this if you're creating a tensor by manipulating another tensor or by using a variation that defaults the device to the input, such as torch.ones_like. In general, use torch.ones_like and torch.zeros_like instead of torch.ones or torch.zeros where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(num_samples, noise_dimension,device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    randn:\n",
    "    Returns a tensor filled with random numbers from a normal distribution\n",
    "    with mean `0` and variance `1` (also called the standard normal\n",
    "    distribution)\n",
    "    \"\"\"\n",
    "    return torch.randn(num_samples,noise_dimension,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the noise vector function\n",
    "def test_get_noise(n_samples, z_dim, device='cpu'):\n",
    "    noise = generate_noise(n_samples, z_dim, device)\n",
    "    \n",
    "    # Make sure a normal distribution was used\n",
    "    assert tuple(noise.shape) == (n_samples, z_dim)\n",
    "    assert torch.abs(noise.std() - torch.tensor(1.0)) < 0.01\n",
    "    assert str(noise.device).startswith(device)\n",
    "\n",
    "test_get_noise(1000, 100, device='cpu')\n",
    "if torch.cuda.is_available():\n",
    "    test_get_noise(1000, 32, 'cuda')\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator\n",
    "<li>The second component that you need to construct is the discriminator. As with the generator component, you will start by creating a function that builds a neural network block for the discriminator.\n",
    "\n",
    "<li>Note: You use leaky ReLUs to prevent the \"dying ReLU\" problem, which refers to the phenomenon where the parameters stop changing due to consistently negative values passed to a ReLU, which result in a zero gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_block(input_dim, output_dim):\n",
    "\n",
    "    \"\"\"\n",
    "    Instead of setting negative values to zero, Leaky ReLU sets negative values to a small negative slope (usually 0.2 or 0.01).\n",
    "    \"\"\"\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=input_dim, out_features=output_dim),\n",
    "        nn.LeakyReLU(0.2, inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the discriminator block function\n",
    "def test_disc_block(in_features, out_features, num_test=10000):\n",
    "    block = get_discriminator_block(in_features, out_features)\n",
    "\n",
    "    # Check there are two parts\n",
    "    assert len(block) == 2\n",
    "    test_input = torch.randn(num_test, in_features)\n",
    "    test_output = block(test_input)\n",
    "\n",
    "    # Check that the shape is right\n",
    "    assert tuple(test_output.shape) == (num_test, out_features)\n",
    "    \n",
    "    # Check that the LeakyReLU slope is about 0.2\n",
    "    assert -test_output.min() / test_output.max() > 0.1\n",
    "    assert -test_output.min() / test_output.max() < 0.3\n",
    "    assert test_output.std() > 0.3\n",
    "    assert test_output.std() < 0.5\n",
    "    \n",
    "    assert str(block.__getitem__(0)).replace(' ', '') == f'Linear(in_features={in_features},out_features={out_features},bias=True)'        \n",
    "    assert str(block.__getitem__(1)).replace(' ', '').replace(',inplace=True', '') == 'LeakyReLU(negative_slope=0.2)'\n",
    "\n",
    "\n",
    "test_disc_block(25, 12)\n",
    "test_disc_block(15, 28)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use these blocks to make a discriminator! The discriminator class holds 2 values:\n",
    "\n",
    "1. The image dimension\n",
    "2. The hidden dimension\n",
    "<li>The discriminator will build a neural network with 4 layers. It will start with the image tensor and transform it until it returns a single number (1-dimension tensor) output. This output classifies whether an image is fake or real. Note that we do not need a sigmoid after the output layer since it is included in the loss function. Finally, to use your discrimator's neural network we are given a forward pass function that takes in an image tensor to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size=28*28, hidden_units=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # linear layer -1\n",
    "            get_discriminator_block(input_dim=image_size, output_dim=hidden_units),\n",
    "            # linear layer -2\n",
    "            get_discriminator_block(input_dim=hidden_units, output_dim=hidden_units*2),\n",
    "            # linear layer -3\n",
    "            get_discriminator_block(input_dim=hidden_units*2,output_dim=hidden_units*2),\n",
    "            # linear layer - 4 i.e output layer\n",
    "            nn.Linear(in_features=hidden_units*2, out_features=1)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self,image):\n",
    "        return self.disc(image)\n",
    "    \n",
    "    #getter\n",
    "    def get_disc(self):\n",
    "        return self.disc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disc = Discriminator().get_disc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disc.__getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the discriminator class\n",
    "def test_discriminator(z_dim, hidden_dim, num_test=100):\n",
    "    \n",
    "    disc = Discriminator(z_dim, hidden_dim).get_disc()\n",
    "\n",
    "    # Check there are three parts\n",
    "    assert len(disc) == 4\n",
    "    assert type(disc.__getitem__(3)) == nn.Linear\n",
    "\n",
    "    # Check the linear layer is correct\n",
    "    test_input = torch.randn(num_test, z_dim)\n",
    "    test_output = disc(test_input)\n",
    "    assert tuple(test_output.shape) == (num_test, 1)\n",
    "\n",
    "test_discriminator(5, 10)\n",
    "test_discriminator(20, 8)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;background-color:DodgerBlue;color:white;\"> Training </h1>\n",
    "<h3> Now you can put it all together! First, we will set our parameters:</h3>\n",
    "\n",
    "<ul>\n",
    "<li>criterion: the loss function\n",
    "<li>n_epochs: the number of times you iterate through the entire dataset when training\n",
    "<li>noise_dim: the dimension of the noise vector\n",
    "<li>display_step: how often to display/visualize the images\n",
    "<li>batch_size: the number of images per forward/backward pass\n",
    "<li>lr: the learning rate\n",
    "<li>device: the device type, here using a GPU (which runs CUDA), not CPU\n",
    "<li>Next, we load the MNIST dataset as tensors using a dataloader.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:DodgerBlue\">Hyper Parameters </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "n_epochs = 10\n",
    "noise_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 16\n",
    "lr = 0.00001\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset as tensors\n",
    "dataloader = DataLoader(\n",
    "    MNIST('data/', download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:DodgerBlue;\">Now lets intialize Generator and Discriminator along with optimizer by passing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(noise_dimension=noise_dim).to(device=device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(),lr=lr)\n",
    "disc = Discriminator().to(device=device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you train your GAN, you will need to create functions to calculate the discriminator's loss and the generator's loss. This is how the discriminator and generator will know how they are doing and improve themselves. Since the generator is needed when calculating the discriminator's loss, you will need to call .detach() on the generator result to ensure that only the discriminator is updated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(num_samples, noise_dim, device, real_images, criterion, generator, discriminator):\n",
    "\n",
    "    \"\"\" \n",
    "    Step 1 : Create Noise using generate_noise function.\n",
    "    Step 2 : generate images from generator by passing noise as input, i.e gen which is intialized.\n",
    "    step 3 : Pass the images generated to the discriminator i.e disc which is intialized, which predict the images fake or real.\n",
    "            Note : Pass the images with detach mode, bcz we are computing here disc loss\n",
    "    step 4 : Compute the loss of discriminator, for the fake images.\n",
    "    step 5 : Pass the real images over the discriminator and get the prediction\n",
    "    step 6 : Compute the loss of discriminator for real images\n",
    "    step 7 : Average the loss for real and fake images\n",
    "    \"\"\"\n",
    "\n",
    "    noise = generate_noise(num_samples=num_samples, noise_dimension=noise_dim, device=device)\n",
    "    fake_images = generator(noise)\n",
    "    disc_fake_images_pred = discriminator(fake_images.detach())\n",
    "    disc_fake_images_loss = criterion(disc_fake_images_pred, torch.zeros_like(disc_fake_images_pred))\n",
    "    disc_real_images_pred = discriminator(real_images)\n",
    "    disc_real_images_loss = criterion(disc_real_images_pred, torch.ones_like(disc_real_images_pred))\n",
    "    disc_loss = (disc_fake_images_loss + disc_real_images_loss) / 2\n",
    "\n",
    "    return  disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator loss function\n",
    "\n",
    "def get_gen_loss(num_samples, noise_dim, device, generator, discriminator, criterion):\n",
    "\n",
    "    \"\"\" \n",
    "    step 1 : Generate Noise\n",
    "    step 2 : Generate the fake images using noise over the generator\n",
    "    step 3 : pass the fake images over the discriminator\n",
    "    step 4 : compute the loss, make sure that the loss is computed over real labels bcz the generator want to fool the discriminator\n",
    "    \"\"\"\n",
    "    noise = generate_noise(num_samples=num_samples, noise_dimension=noise_dim,device=device)\n",
    "    fake_images = generator(noise)\n",
    "    disc_fake_images_pred = discriminator(fake_images)\n",
    "    disc_fake_images_loss = criterion(disc_fake_images_pred, torch.ones_like(disc_fake_images_pred))\n",
    "\n",
    "    return disc_fake_images_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_discriminator_loss =0\n",
    "mean_generator_loss = 0\n",
    "cur_step = 0\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for real_image,_  in tqdm(dataloader):\n",
    "\n",
    "        cur_batch_size = len(real_image)\n",
    "        \n",
    "        \"\"\"\n",
    "        Step 1 : Faltten the image\n",
    "        step 2 : compute the disriminator loss\n",
    "        step 3 : compute gradients w.r.t disc_loss\n",
    "        step 4 : update parameters of discriminator\n",
    "        step 5 : compute generator loss\n",
    "        step 6 : compute gradients w.r.t gen_loss\n",
    "        step 7 : update the parameters of generator\n",
    "        step 8 : \n",
    "+        \n",
    "        \"\"\"\n",
    "        real_image = real_image.view(cur_batch_size,-1).to(device)\n",
    "\n",
    "        # Before computing discriminator loss make sure set disc_opt.zero_grad()\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        # caluclate discriminator loss\n",
    "        disc_loss = get_disc_loss(num_samples=cur_batch_size, noise_dim=noise_dim, device=device, real_images=real_image, criterion=criterion, generator=gen, discriminator=disc)\n",
    "\n",
    "        # compute grads\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "\n",
    "        # update parameters of discriminator\n",
    "        disc_opt.step()\n",
    "\n",
    "        # Before computing generator loss make sure set gen_opt.zero_grad()\n",
    "        gen_opt.zero_grad()\n",
    "\n",
    "        #  Caluclate generator loss\n",
    "        gen_loss = get_gen_loss(num_samples=cur_batch_size, noise_dim=noise_dim, device=device, generator=gen, discriminator=disc, criterion=criterion)\n",
    "\n",
    "        # compute grads no need of retain_graph\n",
    "        gen_loss.backward()\n",
    "\n",
    "        # update the parameters of generator\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            fake_noise = generate_noise(num_samples=cur_batch_size, noise_dimension=noise_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real_image)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
