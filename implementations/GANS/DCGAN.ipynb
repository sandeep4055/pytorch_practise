{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:DodgerBlue;text-align:center;\">Deep Convolutional GAN (DCGAN) </h1>\n",
    "<h3 style=\"color:red;\">Goal</h3>\n",
    "<li>In this notebook, we're going to create another GAN using the MNIST dataset. we will implement a Deep Convolutional GAN (DCGAN), a very successful and influential GAN model developed in 2015.</li>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN\n",
    "<li>Here are the main features of DCGAN :</li>\n",
    "\n",
    "<ol>\n",
    "<li>Use convolutions without any pooling layers</li>\n",
    "<li>Use batchnorm in both the generator and the discriminator</li>\n",
    "<li>Don't use fully connected hidden layers</li>\n",
    "<li>Use ReLU activation in the generator for all layers except for the output, which uses a Tanh activation.</li>\n",
    "<li>Use LeakyReLU activation in the discriminator for all layers except for the output, which does not use an activation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d286837e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;background-color:DodgerBlue;\"> Generator </h1>\n",
    "<li>The first component we will make is the generator. You may notice that instead of passing in the image dimension, we will pass the number of image channels to the generator. This is because with DCGAN, we use convolutions which don’t depend on the number of pixels on an image. However, the number of channels is important to determine the size of the filters.\n",
    "<li>we will build a generator using 4 layers (3 hidden layers + 1 output layer). As before, we will need to write a function to create a single block for the generator's neural network.\n",
    "<li>Since in DCGAN the activation function will be different for the output layer, we will need to check what layer is being created. At the end of the generator class, we are given a forward pass function that takes in a noise vector and generates an image of the output dimension using neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        im_chan: the number of channels of the output image, a scalar\n",
    "              (MNIST is black-and-white, so 1 channel is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        '''\n",
    "        Function to return a sequence of operations corresponding to a generator block of DCGAN, \n",
    "        corresponding to a transposed convolution, a batchnorm (except for in the last layer), and an activation.\n",
    "        Parameters:\n",
    "            input_channels: how many channels the input feature representation has\n",
    "            output_channels: how many channels the output feature representation should have\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "            stride: the stride of the convolution\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "                      (affects activation and batchnorm)\n",
    "        '''\n",
    "\n",
    "        #     Steps:\n",
    "        #       1) Do a transposed convolution using the given parameters.\n",
    "        #       2) Do a batchnorm, except for the last layer.\n",
    "        #       3) Follow each batchnorm with a ReLU activation.\n",
    "        #       4) If its the final layer, use a Tanh activation after the deconvolution.\n",
    "\n",
    "        # Build the neural block\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                #### START CODE HERE ####\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size=kernel_size, stride=stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "                #### END CODE HERE ####\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                #### START CODE HERE ####\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "                #### END CODE HERE ####\n",
    "            )\n",
    "\n",
    "    def unsqueeze_noise(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns a copy of that noise with width and height = 1 and channels = z_dim.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test your make_gen_block() function\n",
    "'''\n",
    "gen = Generator()\n",
    "num_test = 100\n",
    "\n",
    "# Test the hidden block\n",
    "test_hidden_noise = get_noise(num_test, gen.z_dim)\n",
    "test_hidden_block = gen.make_gen_block(10, 20, kernel_size=4, stride=1)\n",
    "test_uns_noise = gen.unsqueeze_noise(test_hidden_noise)\n",
    "hidden_output = test_hidden_block(test_uns_noise)\n",
    "\n",
    "# Check that it works with other strides\n",
    "test_hidden_block_stride = gen.make_gen_block(20, 20, kernel_size=4, stride=2)\n",
    "\n",
    "test_final_noise = get_noise(num_test, gen.z_dim) * 20\n",
    "test_final_block = gen.make_gen_block(10, 20, final_layer=True)\n",
    "test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)\n",
    "final_output = test_final_block(test_final_uns_noise)\n",
    "\n",
    "# Test the whole thing:\n",
    "test_gen_noise = get_noise(num_test, gen.z_dim)\n",
    "test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)\n",
    "gen_output = gen(test_uns_gen_noise)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:DodgerBlue;text-align:center;\">Discriminator</h1>\n",
    "\n",
    "<li>The second component we need to create is the discriminator.\n",
    "\n",
    "<li>We will use 3 layers in our discriminator's neural network. Like with the generator, we will need create the function to create a single neural network block for the discriminator.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator Class\n",
    "    Values:\n",
    "        im_chan: the number of channels of the output image, a scalar\n",
    "              (MNIST is black-and-white, so 1 channel is your default)\n",
    "    hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, im_chan=1, hidden_dim=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "        '''\n",
    "        Function to return a sequence of operations corresponding to a discriminator block of DCGAN, \n",
    "        corresponding to a convolution, a batchnorm (except for in the last layer), and an activation.\n",
    "        Parameters:\n",
    "            input_channels: how many channels the input feature representation has\n",
    "            output_channels: how many channels the output feature representation should have\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "            stride: the stride of the convolution\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "                      (affects activation and batchnorm)\n",
    "        '''\n",
    "        #     Steps:\n",
    "        #       1) Add a convolutional layer using the given parameters.\n",
    "        #       2) Do a batchnorm, except for the last layer.\n",
    "        #       3) Follow each batchnorm with a LeakyReLU activation with slope 0.2.\n",
    "        \n",
    "        # Build the neural block\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                #### START CODE HERE #### #\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "                #### END CODE HERE ####\n",
    "            )\n",
    "        else: # Final Layer\n",
    "            return nn.Sequential(\n",
    "                #### START CODE HERE #### #\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "                #### END CODE HERE ####\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        '''\n",
    "        Function for completing a forward pass of the discriminator: Given an image tensor, \n",
    "        returns a 1-dimension tensor representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor with dimension (im_dim)\n",
    "        '''\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "'''\n",
    "Test our make_disc_block() function\n",
    "'''\n",
    "num_test = 100\n",
    "\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "test_images = gen(get_noise(num_test, gen.z_dim))\n",
    "\n",
    "# Test the hidden block\n",
    "test_hidden_block = disc.make_disc_block(1, 5, kernel_size=6, stride=3)\n",
    "hidden_output = test_hidden_block(test_images)\n",
    "\n",
    "# Test the final block\n",
    "test_final_block = disc.make_disc_block(1, 10, kernel_size=2, stride=5, final_layer=True)\n",
    "final_output = test_final_block(test_images)\n",
    "\n",
    "# Test the whole thing:\n",
    "disc_output = disc(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Test the hidden block\n",
    "assert tuple(hidden_output.shape) == (num_test, 5, 8, 8)\n",
    "# Because of the LeakyReLU slope\n",
    "assert -hidden_output.min() / hidden_output.max() > 0.15\n",
    "assert -hidden_output.min() / hidden_output.max() < 0.25\n",
    "assert hidden_output.std() > 0.5\n",
    "assert hidden_output.std() < 1\n",
    "\n",
    "# Test the final block\n",
    "\n",
    "assert tuple(final_output.shape) == (num_test, 10, 6, 6)\n",
    "assert final_output.max() > 1.0\n",
    "assert final_output.min() < -1.0\n",
    "assert final_output.std() > 0.3\n",
    "assert final_output.std() < 0.6\n",
    "\n",
    "# Test the whole thing:\n",
    "\n",
    "assert tuple(disc_output.shape) == (num_test, 1)\n",
    "assert disc_output.std() > 0.25\n",
    "assert disc_output.std() < 0.5\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "# A learning rate of 0.0002 works well on DCGAN\n",
    "lr = 0.0002\n",
    "\n",
    "# These parameters control the optimizer's momentum, which you can read more about here:\n",
    "# https://distill.pub/2017/momentum/ but you don’t need to worry about it for this course!\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "device = 'cuda'\n",
    "\n",
    "# You can tranform the image values to be between -1 and 1 (the range of the tanh activation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('data/', download=False, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "# You initialize the weights to the normal distribution\n",
    "# with mean 0 and standard deviation 0.02\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        ## Update discriminator ##\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_pred = disc(real)\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "\n",
    "        ## Update generator ##\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
